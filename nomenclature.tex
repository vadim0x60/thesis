\renewcommand\nomgroup[1]{%
  \item[\bfseries
  \ifstrequal{#1}{R}{Reinforcement Learning}{%
  \ifstrequal{#1}{G}{Program Synthesis}{%
  \ifstrequal{#1}{E}{Software Engineering}
  \ifstrequal{#1}{S}{Statistics}{}}}%
]}

\nomenclature[G]{PBE}{Programming by example, see \ref{sec:taxonomy}}

\nomenclature[R]{POMDP}{Partically Observable Markov Decision Process, see \ref{sec:taxonomy}}

\nomenclature[E]{CAE}{Computer-Aided Software Engineering, see \ref{sec:human}}

\nomenclature[G]{AST}{Abstract Syntax Tree, see \ref{sec:grammar-guided}}

\newcommand{\inputvec}{X}
\nomenclature[G]{$\inputvec$}{a vector of input examples in a PBE system}

\newcommand{\outputvec}{Y}
\nomenclature[G]{$\outputvec$}{a vector of output examples a PBE system}

\newcommand{\rlobsspace}{\mathcal{O}}
\nomenclature[R]{$\rlobsspace$}{observation space of a POMDP}

\newcommand{\rlstatespace}{\mathcal{S}}
\nomenclature[R]{$\rlstatespace$}{set of all possible states of a POMDP}

\newcommand{\rlactionspace}{\mathcal{A}}
\nomenclature[R]{$\rlactionspace$}{action space of a POMDP}

\newcommand{\rlreturn}{R_n}
\nomenclature[R]{$\rlreturn$}{n-step return in a POMDP}

\newcommand{\rlstatedistr}{p_s(s_{i+1} | s_i, a_i)}
\nomenclature[R]{$\rlstatedistr$}{state distribution of a POMDP}

\newcommand{\rlobsdistr}{p_o(o_i | s_i, a_i)}
\nomenclature[R]{$\rlobsdistr$}{observation distribution of a POMDP}

\newcommand{\rlrewardf}{r(s_i,a_i)}
\nomenclature[R]{$\rlrewardf$}{reward function in a POMDP}

\newcommand{\alphabet}{\mathcal{L}}
\nomenclature[G]{$\alphabet$}{the alphabet of a programming language (set of all possible tokens)}

\newcommand{\code}{c}
\nomenclature[G]{$\code$}{a sequence of tokens $c1,c2,\dots$ that constitutes a program}

\newcommand{\expectation}{\mathbb{E}}
\nomenclature[S]{$\expectation$}{expected value}