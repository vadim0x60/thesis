\nomenclature{PBE}{Programming by example \cite{gulwani2016:programming, halbertProgrammingExample1984}}
\nomenclature{PIRL}{Programmatically Interpretable Reinforcement Learning \cite{pirl}}
\nomenclature{PatientSPIRL}{Patient Simulator Programmatically Interpretable Reinforcement Learning, introduced in chapter \ref{ch:proposal}}

\nomenclature{RL}{Reinforcement Learning \cite{suttonReinforcementLearningSecond2018}}
\nomenclature{PQT}{Priority Queue Training \cite{abolafiaNeuralProgramSynthesis2018}}
\nomenclature{POMDP}{Partially Observable Markov Decision Process \cite{kramerjdavidrPartiallyObservableMarkov1964}}
\nomenclature{MPC}{Model Predictive Control \cite{garciaModelPredictiveControl1989, holkarOverviewModelPredictive2010, kouvaritakisModelPredictiveControl2016, schwenzerReviewModelPredictive2021}}
\nomenclature{MDPD}{Message Passing Decision Process, introduced in section \ref{sec:mpdp}}

\nomenclature{GPT}{Generative Pre-trained Transformer \cite{radfordImprovingLanguageUnderstandinga}}
\nomenclature{LLM}{Large Language Model}
\nomenclature{AI}{Artificial Intelligence}

\nomenclature{CASE}{Computer-Aided Software Engineering \cite{ComputeraidedSoftwareEngineering2025}}
\nomenclature{AST}{Abstract Syntax Tree, see \ref{sec:grammar-guided}}

\nomenclature{SEIDR}{Synthesize Execute Debug Rank, introduced in chapter \ref{ch:seidr}}

\nomenclature{MHE}{Moving Horizon Estimator}

\nomenclature{CAPFT}{Capacity modifier function with temperature}
\nomenclature{CO2}{Carbon dioxide}
\nomenclature{EIR}{Energy input ratio}
\nomenclature{EIRFT}{Energy input ratio function with temperature}
\nomenclature{EIRFPLR}{Energy input ratio function with partial load ratio}
\nomenclature{HVAC}{Heating Ventilation Air Conditioning}
\nomenclature{IDEAS}{Integrated District Energy Assessment Simulations}
\nomenclature{IPOPT}{Interior Point Optimizer}
\nomenclature{KPI}{Key Performance Indicator}
\nomenclature{PI}{Proportional Integral}
\nomenclature{PLR}{Partial load ratio}
\nomenclature{RC}{Resistance capacitance}

\nomenclature{ALS}{Advanced Life Support \cite{AMLSAdvancedMedical2021}}

\newcommand{\obs}{\mathbf{o}}
\nomenclature{$\obs$}{a single observation of an agent}

\newcommand{\policy}{\pi}
\nomenclature{$\policy(\action)$}{a \emph{policy distribution} that stochastically defines the agent's actions}
\nomenclature{$\policy(\text{text})$}{language model (probability distribution over texts)}

\newcommand{\discretebins}{\Upsilon^\text{bins}}
\nomenclature{$\discretebins$}{number of discretization bins}

\newcommand{\historylen}{\Upsilon^\text{history}}
\nomenclature{$\historylen$}{history length, the number of past steps considered by the algorithm}

\newcommand{\mlinput}{x}
\newcommand{\mlinputvec}{\mathbf{x}}
\nomenclature{$\mlinput$, $\mlinputvec$}{input examples in a machine learning system}

\newcommand{\step}{i}
\newcommand{\stepp}{j}
\newcommand{\steppp}{k}
\nomenclature{$\step$,$\stepp$,$\steppp$}{iteration, step, moment in discrete time}

\newcommand{\mloutput}{y}
\newcommand{\mloutputvec}{\mathbf{y}}
\nomenclature{$\mloutput$, $\mloutputvec$}{expected output examples in a machine learning system}

\newcommand{\obss}{\mathcal{O}}
\nomenclature{$\obss$}{set of all possible observations $\obs$}

\newcommand{\state}{\textbf{s}}
\nomenclature{$\state$}{a state of an environment}

\newcommand{\states}{\mathcal{S}}
\nomenclature{$\states$}{set of all possible states $\state$ of an environment}

\newcommand{\termstates}{\mathcal{S}_t}
\nomenclature{$\termstates$}{set of all terminal states $\state$ of an environment}

\newcommand{\nontermstates}{\mathcal{S}_{nt}}
\nomenclature{$\nontermstates$}{set of all non-terminal states $\state$ of an environment}

\newcommand{\action}{a}
\nomenclature{$\action$}{an action of an agent}

\newcommand{\actions}{\mathcal{A}}
\nomenclature{$\actions$}{set of all possible actions $\action$}

\newcommand{\actionqueue}{\alpha}
\nomenclature{$\actionqueue$}{action queue of an agent}

\newcommand{\reward}{r}
\nomenclature{$\reward$}{a reward}

\newcommand{\returnn}{R_n}
\nomenclature{$\returnn$}{n-step return}

\newcommand{\returntot}{R_\text{tot}}
\nomenclature{$\returntot$}{total episode return}

\newcommand{\realnums}{\mathbb{R}}
\nomenclature{$\realnums$}{real numbers}

\newcommand{\memory}{m}
\nomenclature{$\memory$}{memory of an agent}

\newcommand{\alphabet}{\aleph}
\nomenclature{$\alphabet$}{the alphabet of a programming language (set of all possible tokens $\token$)}

\newcommand{\token}{c}
\nomenclature{$\token$}{a \emph{token}, a minimal unit of code, such as a character}

\newcommand{\code}{\mathcal{C}}
\nomenclature{$\code$}{\emph{program code}, a sequence of tokens $\token_1,\token_2,\dots$ that constitutes a program}

\newcommand{\codebase}{\kappa}
\nomenclature{$\codebase$}{\emph{codebase}, a population of programs}

\newcommand{\expectation}{\mathbb{E}}
\nomenclature{$\expectation$}{expected value}

\newcommand{\loss}{\lambda}
\nomenclature{$\loss(x)$}{a differentiable loss function to be minimized by an optimization algorithm}

\newcommand{\obj}{\omega}
\nomenclature{$\obj(x)$}{an objective function to be maximized by an optimization algorithm}

\newcommand{\learnables}{\Phi}
\nomenclature{$\learnables$}{learnable parameters of a model}

\newcommand{\weights}{\mathbf{W}}
\nomenclature{$\weights$}{weight matrix in a model, element of $\learnables$}

\newcommand{\biases}{\mathbf{b}}
\nomenclature{$\biases$}{bias vector in a model, element of $\learnables$}

\newcommand{\hidden}{\mathbf{h}}
\nomenclature{$\hidden$}{a hidden state within a model}

\newcommand{\latent}{\mathbf{z}}
\nomenclature{$\latent$}{a latent representation of input $\mlinput$}

\newcommand{\mean}{\boldsymbol\mu}
\nomenclature{$\mean$}{mean}

\newcommand{\stddev}{\boldsymbol\sigma}
\nomenclature{$\stddev$}{variance}

\newcommand{\normaldistr}{\nu}
\nomenclature{$\normaldistr(\mean,\stddev)$}{the normal distribution}

\newcommand{\pointer}{P}
\nomenclature{$\pointer$}{pointer}

\newcommand{\prob}{p}
\nomenclature{$\prob(x)$}{a probability distribution}

\newcommand{\team}{\Xi}
\nomenclature{$\team$}{a cooperative \emph{team} of agents}

\newcommand{\temp}{T}
\nomenclature{$\temp$}{sampling temperature}
\nomenclature{$\temp$}{physical temperature}

\newcommand{\timepoint}{t}
\nomenclature{$\timepoint$}{a moment in continuous time}

\newcommand{\threshold}{\theta}
\nomenclature{$\threshold$}{threshold value for discretization}

\newcommand{\hyperparam}{\Upsilon}
\nomenclature{$\Upsilon$}{hyperparameter of an algorithm}

\newcommand{\beamwidth}[0]{\hyperparam^\text{beam}}
\nomenclature{$\beamwidth$}{beam width in beam search}

\newcommand{\treearity}[0]{\hyperparam^\text{tree}}
\nomenclature{$\treearity$}{tree arity, as in $\treearity$-ary tree}

\newcommand{\integers}{\mathbb{Z}}
\nomenclature{$\integers$}{integers}

\newcommand{\treenode}{\delta}
\nomenclature{$\treenode$}{a node in a tree}

\newcommand{\kldivergence}{D_{KL}}
\nomenclature{$\kldivergence(\prob_L \parallel \prob_R)$}{Kullback Leibner divergence between probability distributions $\prob_L(x)$ and $\prob_R(x)$, $\sum_x \prob_L(x)\ \log\left(\frac{\ \prob_L(x)\ }{ \prob_R(x) }\right)$}

\newcommand{\identitymatrix}{I}
\nomenclature{$\identitymatrix$}{identity matrix}

\newcommand{\regularization}{\hyperparam^\text{regularization}}
\nomenclature{$\regularization$}{weight of a regularization term in $\obj(x)$}

\newcommand{\greed}{\hyperparam^\text{greed}}
\nomenclature{$\greed$}{greed level setting for a greedy algorithm}

\newcommand{\probs}{\mathcal{P}}
\nomenclature{$\probs$}{a set or tuple of probability distributions}

\newcommand{\statevalue}{V}
\nomenclature{$\statevalue(\state)$}{value of a state in reinforcement learning}

\printnomenclature

\emph{A note on notation:} bold lowercase characters $\mathbf{x}$ represent vectors, bold uppercase characters $X$ represent matrices, calligraphic letters $\mathcal{X}$ represent sets and tuples. This holds for functions as well, i.e. $f(\mathbf{x})$ maps vectors to scalars